# ğŸ” BÃºsquedas Informadas

Las **bÃºsquedas informadas** utilizan conocimiento adicional (una **heurÃ­stica**) para guiar la exploraciÃ³n del espacio de estados hacia el objetivo. A diferencia de las bÃºsquedas no informadas (BFS, DFS, UCS), que exploran ciegamente, las informadas tratan de ser **inteligentes** para ahorrar tiempo y memoria.

---

## â­ A*:

### âœ… FunciÃ³n de evaluaciÃ³n
La funciÃ³n de prioridad central de A* es:
$$
f(n) = g(n) + h(n)
$$
- \(g(n)\): costo real desde el inicio hasta el nodo \(n\).
- \(h(n)\): estimaciÃ³n heurÃ­stica desde \(n\) hasta el objetivo.
- A* siempre expande el nodo con el menor \(f(n)\) en cada paso.

### âœ… Condiciones para optimalidad
- Si \(h(n)\) es **admisible** (no sobreestima el costo real restante), A* es **Ã³ptimo** (encuentra la soluciÃ³n de menor costo).
- Si \(h(n)\) es **consistente (o monÃ³tona)**, A* tambiÃ©n es **Ã³ptimo** y ademÃ¡s puede garantizar que un nodo se expande como mucho una vez. Esto mejora eficiencia.
    - Una heurÃ­stica es **consistente** si:
$$
h(n) \leq c(n, n') + h(n')
$$
    Donde \(c(n, n')\) es el costo de ir de \(n\) a \(n'\). Es decir, la heurÃ­stica no puede "saltar" y sobreestimar el costo de un paso.

---

## ğŸ“Š BÃºsqueda Ã“ptima vs Eficiencia

| Propiedad | Con heurÃ­stica admisible | Con heurÃ­stica consistente |
|---|---|---|
| Optimalidad | âœ”ï¸ | âœ”ï¸ |
| ExpansiÃ³n de nodos | Puede expandir un nodo varias veces | Cada nodo expandido a lo sumo 1 vez |

---

## ğŸ§© Ejemplos de heurÃ­sticas

Para el **8 puzzle**:
- **h1 = nÃºmero de piezas mal colocadas** (simple, admisible, pero no muy precisa).
- **h2 = suma de distancias Manhattan** (mÃ¡s precisa, aÃºn admisible).

En general, **heurÃ­sticas mÃ¡s informativas (mÃ¡s altas sin sobreestimar)** reducen el nÃºmero de nodos expandidos.

---

## âš ï¸ HeurÃ­sticas no admisibles
- Si la heurÃ­stica **sobreestima**, A* puede ser mÃ¡s rÃ¡pido, pero deja de ser Ã³ptimo.
- Ejemplo: una heurÃ­stica que ignora obstÃ¡culos puede dar rutas imposibles.

---

## âš”ï¸ ComparaciÃ³n con otras bÃºsquedas informadas

| Algoritmo | FunciÃ³n de evaluaciÃ³n | Optimalidad | CaracterÃ­stica clave |
|---|---|---|---|
| **Greedy Best-First** | \(f(n) = h(n)\) | âŒ | Solo sigue la heurÃ­stica |
| **A*** | \(f(n) = g(n) + h(n)\) | âœ”ï¸ (con \(h\) admisible) | Combina costo real y estimado |

- **Greedy Best-First Search**: RÃ¡pida en espacios grandes, pero puede atascarse en caminos subÃ³ptimos.
- **A***: MÃ¡s lenta si la heurÃ­stica es mala, pero garantiza el mejor camino.

---

## ğŸ“ Dominancia de heurÃ­sticas

Si tienes dos heurÃ­sticas \(h_1\) y \(h_2\):
- \(h_1\) **domina** a \(h_2\) si:
$$
\forall n \quad h_1(n) \geq h_2(n)
$$
- Usar una heurÃ­stica mÃ¡s fuerte (mÃ¡s cercana al costo real) suele reducir la cantidad de nodos expandidos.

---

## ğŸ§µ Otras tÃ©cnicas relacionadas

### âœ… IDA* (Iterative Deepening A*)
- A* puede consumir mucha memoria (guarda todos los nodos en memoria).
- **IDA*** es una versiÃ³n que usa *backtracking* (como DFS) pero con un umbral de costo \(f\). Se ajusta en cada iteraciÃ³n.
- Menor memoria, pero puede ser mÃ¡s lento.

### âœ… Weighted A*
- Modifica:
$$
f(n) = g(n) + w \cdot h(n)
$$
- Si \(w > 1\), da mÃ¡s peso a la heurÃ­stica. Es **mÃ¡s rÃ¡pido**, pero puede perder optimalidad.
- Permite **ajustar la rapidez vs calidad**.

---

## ğŸ Comparativa General

| Algoritmo | Optimalidad | Eficiencia |
|---|---|---|
| BFS (costo uniforme si hay pesos) | âœ”ï¸ (con pesos iguales) | âŒ (explora todo) |
| UCS | âœ”ï¸ | âŒ |
| Greedy Best-First | âŒ | âœ”ï¸ |
| A* | âœ”ï¸ (con h admisible) | âœ”ï¸ (con buena heurÃ­stica) |
| IDA* | âœ”ï¸ (con h admisible) | âœ”ï¸ (baja memoria) |

---

## ğŸ”¥ Idea central

La clave en **bÃºsqueda informada** es encontrar una buena **heurÃ­stica**:
- **Admisible**: no sobreestima.
- **Informativa**: lo mÃ¡s cercana posible al costo real.
- **Consistente** (ideal): garantiza no expandir nodos mÃºltiples veces.

